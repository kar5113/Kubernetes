#### Installing kubernetes with aws eksctl
  1. Install kubectl command line tool
    For linux:
    ```bash
    curl -O https://s3.us-west-2.amazonaws.com/amazon-eks/1.34.2/2025-11-13/bin/linux/amd64/kubectl
    chmod +x ./kubectl
    mkdir -p $HOME/bin && cp ./kubectl $HOME/bin/kubectl && export PATH=$HOME/bin:$PATH 

  2. Install eksctl command line tool
    For linux:
    ```bash
    # for ARM systems, set ARCH to: `arm64`, `armv6` or `armv7`
    ARCH=amd64
    PLATFORM=$(uname -s)_$ARCH
    curl -sLO "https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_$PLATFORM.tar.gz"
    # (Optional) Verify checksum
    curl -sL "https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_checksums.txt" | grep $PLATFORM | sha256sum --check
    tar -xzf eksctl_$PLATFORM.tar.gz -C /tmp && rm eksctl_$PLATFORM.tar.gz
    sudo install -m 0755 /tmp/eksctl /usr/local/bin && rm /tmp/eksctl 

  3. Create a kubernetes cluster with eksctl
    ```bash
    eksctl create cluster --name=<cluster-name> --region=<aws-region> --nodes=<number-of-nodes> --node-type=<instance-type>
    # Example:
    eksctl create cluster --config-file=cluster-config.yaml
    eksctl delete cluster --config-file=cluster-config.yaml



#### kubernetes commands
- kubectl api-resources
- kubectl get nodes    
- kubectl get pods
- kubectl get services
- kubectl get deployments
- kubectl describe pod <pod-name>
- kubectl describe service <service-name>
- kubectl describe deployment <deployment-name>
- kubectl logs <pod-name>
- kubectl apply -f <file.yaml>
- kubectl delete -f <file.yaml>
- kubectl exec -it <pod-name> -- /bin/bash
- kubectl scale deployment <deployment-name> --replicas=<number-of-replicas>
- kubectl port-forward <pod-name> <local-port>:<pod-port>
- kubectl get namespaces
- kubectl create namespace <namespace-name>
- kubectl delete namespace <namespace-name>
- kubectl config use-context <context-name>
- kubectl get all -n <namespace-name>
- kubectl exec -it <pod-name> -c <container-name> -- <command> # Execute command in specific container within a pod
- kubectl exec -it <pod-name> -- <command> # Execute command in the first container of the pod if multiple containers exist or single container pod
- kubectl config set-context --current --namespace=roboshop-dev # Set default namespace for current context or use kubens...
- kubectx <context-name> # Switch between contexts easily using kubectx tool when multiple clusters are used
- kubens <namespace-name> # Switch between namespaces easily using kubens tool when multiple namespaces are used
- kubectl get nodes --show-labels # Show labels of nodes for getting selectors.



#### kubernetes resource types
- Pods
- Services
- Deployments
- ReplicaSets
- Namespaces
- ConfigMaps
- Secrets
- PersistentVolumes
- PersistentVolumeClaims
- StatefulSets
- DaemonSets
- Ingress   
- Jobs
- CronJobs




#### Kubernetes notes
- namespace:
    - used to create multiple virtual clusters within a single physical cluster
    - useful for separating environments (e.g., development, staging, production) or teams within an organization
    - resources within a namespace are isolated from those in other namespaces
    - default namespace is "default"
    - can create custom namespaces using YAML files or kubectl commands
- pod: 
    - smallest and simplest Kubernetes object
    - represents a single instance of a running process in a cluster
    - can contain one or more containers that share the same network namespace and storage
    - pods are ephemeral and can be created, destroyed, and recreated as needed
    - managed by higher-level controllers like Deployments or StatefulSets for scalability and availability   
- labels:
    - key-value pairs attached to Kubernetes objects (e.g., pods, services, deployments)
    - used for organizing, selecting, and filtering resources
    - facilitate grouping and managing resources based on specific criteria
    - can be used in conjunction with selectors to perform operations on a subset of resources
    - labels are flexible and can be added or modified at any time without affecting the underlying resources
- Annotations:
    - key-value pairs attached to Kubernetes objects
    - used to store non-identifying metadata that can be used by tools and libraries
    - typically used for configuration or operational information that is not relevant for selection or grouping
    - unlike labels, annotations are not used for selecting or filtering resources
    - can be added or modified at any time without affecting the underlying resources 
    - special characters are allowed in annotation keys and values, making them suitable for storing larger or more complex data   
## Annotations vs labels
| Feature        | Labels                                           | Annotations                                     |
|----------------|--------------------------------------------------|-------------------------------------------------|
| Purpose        | Used for identifying and grouping resources      | Used for storing non-identifying metadata       |
| Selection      | Can be used with selectors to filter resources   | Not used for selection or filtering             |
| Metadata Type  | Key-value pairs                                  | Key-value pairs                                 | 
| Use Cases      | Organizing resources, managing deployments       | Storing configuration or operational information|
| Modification   | Can be added or modified at any time             | Can be added or modified at any time            |    
| Special Chars  | Limited to alphanumeric characters, '-', '_'     | Allows special characters, larger data          |

- pod/container resources:
    - requests:
        - specify the minimum amount of CPU and memory resources required for a container to run
        - used by the Kubernetes scheduler to determine which node can accommodate the pod
        - ensures that the container has enough resources to function properly
    - limits:
        - specify the maximum amount of CPU and memory resources that a container can use
        - prevent a container from consuming excessive resources and impacting other containers on the same node
        - if a container exceeds its resource limits, it may be throttled or terminated by the kubelet
    - it is important to set appropriate resource requests and limits to ensure optimal performance and stability of applications running in Kubernetes

- Config maps:
    - used to store non-confidential configuration data in key-value pairs
    - allow separation of configuration from application code, making it easier to manage and update configurations without modifying the application
    - can be created using YAML files or kubectl commands
    - can be consumed by pods as environment variables, command-line arguments, or mounted as files in a volume
    - useful for managing application settings, feature flags, and other configuration data that may change frequently    

- Secrets:
    - used to store sensitive information such as passwords, API keys, and certificates
    - data is stored in an encoded format (base64) to provide a basic level of obfuscation
    - can be created using YAML files or kubectl commands
    - can be consumed by pods as environment variables or mounted as files in a volume
    - help enhance security by keeping sensitive data separate from application code and configuration

- Services:
They are used to achieve pod communication and load balancing in a Kubernetes cluster and expose applications running on a set of pods. Key points about services:
    - an abstraction that defines a logical set of pods and a policy to access them
    - provide stable IP addresses and DNS names for accessing pods, even as the underlying pods are created and destroyed
    - enable load balancing and service discovery within the cluster
    - can be exposed externally to allow access from outside the cluster
    - use selectors to identify the pods that belong to the service based on labels
There are four main types of services in Kubernetes:
    - ClusterIP (default): For internal communication within the cluster
        - exposes the service on a cluster-internal IP
        - accessible only within the cluster
        - used for communication between pods within the cluster
    - NodePort: For external access to the service
        - exposes the service on each node's IP at a static port (the NodePort)
        - accessible from outside the cluster using <NodeIP>:<NodePort>
        - useful for development and testing purposes
    - LoadBalancer: For external access with load balancing
        - provisions an external load balancer (if supported by the cloud provider)
        - exposes the service to the internet using a public IP address
        - routes traffic to the appropriate pods based on load balancing algorithms
    - ExternalName:
        - maps the service to an external DNS name
        - does not create a traditional service with selectors or endpoints
        - useful for integrating with external services outside the cluster    

- Replicasets:
    - ensure that a specified number of pod replicas are running at any given time
    - monitor the state of pods and create or delete pods as needed to maintain the desired number of replicas
    - provide high availability and fault tolerance for applications by distributing pod replicas across multiple nodes
    - can be created and managed using YAML files or kubectl commands
    - often used in conjunction with Deployments, which provide additional features such as rolling updates and rollbacks

- Deployment:
    - a higher-level abstraction that manages ReplicaSets and provides declarative updates to applications
    - allows you to define the desired state of your application, including the number of replicas, container images, and update strategies
    - automatically creates and manages ReplicaSets to ensure that the desired number of pod replicas are running
    - supports rolling updates, allowing you to update your application with zero downtime by gradually replacing old pods with new ones
    - provides rollback capabilities, enabling you to revert to a previous version of your application if needed
    - can be created and managed using YAML files or kubectl commands  

- Volumes:
    - provide persistent storage for pods in a Kubernetes cluster
    - allow data to persist beyond the lifecycle of individual pods, enabling stateful applications
    - can be used to share data between containers within the same pod
    - support various types of storage backends, including local storage, network-attached storage, and cloud-based storage solutions
    - can be defined in pod specifications and mounted into containers at specified paths
    - help ensure data durability and availability for applications running in Kubernetes

    - There are several types of volumes in Kubernetes, including:
        - emptyDir: A temporary directory that is created when a pod is assigned to a node and exists as long as the pod is running. It is useful for sharing data between containers in the same pod. For example , a web server container and a logging container can share log files using an emptyDir volume.
        - hostPath: Mounts a file or directory from the host node's filesystem into the pod. Useful for accessing host resources or sharing data between pods on the same node.
        - persistent Volume: Represents a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using StorageClasses. It is used to provide persistent storage for pods.
        - persistentVolumeClaim: Uses a PersistentVolumeClaim to request storage from a PersistentVolume and mount it into a pod. It is dynamically provisioned based on the claim's specifications.
        - configMap: Mounts a ConfigMap as a volume, allowing pods to consume configuration data
        - secret: Mounts a Secret as a volume, enabling pods to access sensitive information securely
        - nfs, awsElasticBlockStore, gcePersistentDisk, and others: Support for various external storage systems        

- Horizontal Pod Autoscaler (HPA):
    - automatically scales the number of pod replicas in a deployment or replica set based on observed CPU utilization or other select metrics
    - helps ensure that applications can handle varying levels of traffic and workload by adjusting the number of running pods as needed
    - can be configured using YAML files or kubectl commands
    - supports custom metrics in addition to CPU utilization for scaling decisions
    - improves application availability and performance by dynamically adapting to changing resource demands
    - requires the Metrics Server to be deployed in the cluster to collect resource usage data
    - can be created using the `kubectl autoscale` command or by defining an HPA resource in a YAML file
    - allows you to specify minimum and maximum replica counts, as well as target CPU utilization or custom metrics for scaling decisions
    - helps optimize resource usage and costs by scaling down when demand is low and scaling up when demand increases
    - requires proper resource requests and limits to be set on the pods for effective scaling

 - Vertical Pod Autoscaler (VPA):
    - automatically adjusts the CPU and memory resource requests and limits for containers in pods based on observed usage
    - helps ensure that applications have the appropriate resources to operate efficiently without over-provisioning or under-provisioning
    - can be configured using YAML files or kubectl commands
    - supports three modes: "Off" (no adjustments), "Auto" (automatic adjustments), and "Recreate" (restarts pods to apply new resource settings)
    - improves application performance and stability by adapting to changing resource demands over time
    - can be used in conjunction with Horizontal Pod Autoscaler (HPA) for comprehensive scaling strategies
    - requires the VPA admission controller to be enabled in the cluster for automatic resource adjustments
    - helps optimize resource usage and costs by ensuring that pods have the right amount of resources based on actual usage patterns   



   
    


#### Errors
- CrashLoopBackOff:
    - indicates that a container in a pod is repeatedly crashing and restarting
    - common causes include application errors, misconfigurations, or resource constraints
    - to troubleshoot, check the container logs using `kubectl logs <pod-name>` and inspect the pod description with `kubectl describe pod <pod-name>`
    - ensure that the container image is correct and that all required dependencies are available
    - consider adding readiness and liveness probes to monitor the health of the application within the container
- ImagePullBackOff:
    - indicates that Kubernetes is unable to pull the specified container image from the container registry
    - common causes include incorrect image names, missing tags, or authentication issues with private registries
    - to troubleshoot, check the pod description with `kubectl describe pod <pod-name>` to see detailed error messages related to image pulling
    - verify that the image name and tag are correct and that the container registry is accessible
    - if using a private registry, ensure that the necessary image pull secrets are configured in the pod specification



## Useful stuff

- liveness and readiness probes:
    - used to monitor the health and availability of containers within a pod
    - liveness probes determine if a container is running and healthy; if the probe fails, the container is restarted
    - readiness probes determine if a container is ready to accept traffic; if the probe fails, the pod is removed from service endpoints
    - can be configured using various methods such as HTTP requests, TCP socket checks, or command execution
    - help improve application reliability and availability by ensuring that only healthy containers receive traffic and that unhealthy containers are automatically recovered
liveness prove vs readiness probe:
| Feature            | Liveness Probe                               | Readiness Probe                                     |
|--------------------|----------------------------------------------|-----------------------------------------------------|
| Purpose            | Checks if the container is alive and healthy | Checks if the container is ready to serve traffic.  |
| Action on Failure  | Restarts the container                       | Removes the pod from service endpoints              |
| Use Case           | Detects and recovers from application crashes| Manages traffic routing based on container readiness|
| Configuration      | Can use HTTP, TCP, or command execution      | Can use HTTP, TCP, or command execution             |
| Impact on Traffic  | No direct impact on traffic routing          | Directly affects traffic routing to the pod         |




- kubectx and kubens:
    - kubectx is a command-line tool that simplifies switching between multiple Kubernetes contexts (clusters)
    - kubens is a command-line tool that simplifies switching between multiple Kubernetes namespaces within a cluster
    - both tools enhance productivity by allowing users to quickly change their working context or namespace without manually editing the kubeconfig file
    - can be installed using package managers like Homebrew or by downloading precompiled binaries from their respective GitHub repositories
    - once installed, users can switch contexts with `kubectx <context-name>` and switch namespaces with `kubens <namespace-name>`


- configmap vs secret:
| Feature        | ConfigMap                                      | Secret                                           |
|----------------|------------------------------------------------|-------------------------------------------------|
| Purpose        | Stores non-confidential configuration data     | Stores sensitive information                     |
| Data Encoding  | Plain text                                     | Base64 encoded                                  |
| Use Cases      | Application settings, feature flags            | Passwords, API keys, certificates                  |
| Access Methods | Environment variables, volume mounts           | Environment variables, volume mounts             |
| Security       | Not encrypted, suitable for non-sensitive data | Provides basic obfuscation, suitable for sensitive data |   

when config mapchanged, pods or deployments using it need to be restarted to pick up the changes. Secrets behave similarly. 


- EBS 
    - To mount an EBS volume to a pod, you need to create a PersistentVolume (PV) and a PersistentVolumeClaim (PVC) that references the EBS volume.
      Then you can mount the PVC to the pod in the pod specification.
    - EBS volumes are specific to a single availability zone, so ensure that your pods are scheduled in the same zone as the EBS volume.
    - EBS volumes can be dynamically provisioned using StorageClasses, allowing for automatic creation and management of EBS volumes based on PVC requests.
    - Install the AWS EBS CSI driver in your Kubernetes cluster to enable dynamic provisioning and management of EBS volumes.
        kubectl apply -k "github.com/kubernetes-sigs/aws-ebs-csi-driver/deploy/kubernetes/overlays/stable/?ref=release-1.53"
    - EC2 instances (nodes) must have the necessary IAM permissions to access and manage EBS volumes.
    - Create PV 

- EFS
    - To mount an EFS volume to a pod, you need to create a PersistentVolume (PV) and a PersistentVolumeClaim (PVC) that references the EFS file system.
      Then you can mount the PVC to the pod in the pod specification.
    - EFS volumes are accessible across multiple availability zones, making them suitable for applications that require shared storage.
    - Install the AWS EFS CSI driver in your Kubernetes cluster to enable dynamic provisioning and management of EFS volumes.
        kubectl kustomize \
    "github.com/kubernetes-sigs/aws-efs-csi-driver/deploy/kubernetes/overlays/stable/?ref=release-2.2" > public-ecr-driver.yaml
    - EC2 instances (nodes) must have the necessary IAM permissions to access and manage EFS file systems.
    - Create PV and PVC for EFS and mount it to pods as needed.
    - Create a security group that allows NFS traffic (port 2049) between the EFS file system and the EC2 instances (nodes) in your Kubernetes cluster.

- EBS vs EFS:
| Feature               | EBS (Elastic Block Store)                     | EFS (Elastic File System)                     |
|-----------------------|-----------------------------------------------|-------------------------------------------------|
| Storage Type          | Block storage                                 | File storage                                   |
| Accessibility         | Accessible by a single EC2 instance at a time | Accessible by multiple EC2 instances simultaneously |
| Use Cases             | Databases, file systems, applications requiring low-latency access | Shared file storage, content management systems, home directories |
| Performance           | High performance for single-instance workloads | Scalable performance for multi-instance workloads |
| Durability            | Data is replicated within a single availability zone | Data is replicated across multiple availability zones |
| Cost                  | Generally lower cost for single-instance use cases | Generally higher cost due to multi-instance access and scalability | 
| Mounting in Pods     | Requires PV and PVC for mounting               | Requires PV and PVC for mounting                 |
| Dynamic Provisioning | Supported with AWS EBS CSI driver                | Supported with AWS EFS CSI driver                |
| IAM Permissions      | Required for EC2 instances to manage EBS volumes | Required for EC2 instances to manage EFS file systems |
| Performance Modes     | General Purpose (gp2, gp3), Provisioned IOPS (io1, io2) | Bursting Throughput, Provisioned Throughput      |
| Scalability          | Up to 16 TiB per volume                        | Scales up to petabytes automatically            |
| Backup and Snapshots | Supports snapshots for data backup and recovery | Supports backups through AWS Backup service      |
| Data Sharing        | Not designed for data sharing between instances | Designed for concurrent access by multiple instances |
| Integration with AWS Services | Integrates with EC2, RDS, and other services | Integrates with EC2, ECS, EKS, and other services |
| Performance Consistency | Provides consistent performance for single-instance workloads | Performance may vary based on the number of concurrent connections and workload |
| Security            | Supports encryption at rest and in transit     | Supports encryption at rest and in transit       |
| Security groups      | EBS volumes inherit the security groups of the EC2 instance | EFS file systems can be associated with specific security groups |        


#### sets 

- Replica set:
    - ensures that a specified number of pod replicas are running at any given time
    - monitors the state of pods and creates or deletes pods as needed to maintain the desired number of replicas
    - provides high availability and fault tolerance for applications by distributing pod replicas across multiple nodes
    - can be created and managed using YAML files or kubectl commands
    - often used in conjunction with Deployments, which provide additional features such as rolling updates and rollbacks

- Deployment:
    - a higher-level abstraction that manages ReplicaSets and provides declarative updates to applications
    - allows you to define the desired state of your application, including the number of replicas, container images, and update strategies
    - automatically creates and manages ReplicaSets to ensure that the desired number of pod replicas are running
    - supports rolling updates, allowing you to update your application with zero downtime by gradually replacing old pods with new ones
    - provides rollback capabilities, enabling you to revert to a previous version of your application if needed
    - can be created and managed using YAML files or kubectl commands
    - It is for stateless applications where any pod can handle any request

- DaemonSets:
    - ensure that a copy of a specific pod is running on all (or a subset of) nodes in a Kubernetes cluster
    - commonly used for deploying system-level services such as log collectors, monitoring agents, or network plugins or logging agents.
    - automatically adds pods to new nodes as they are added to the cluster and removes pods from nodes that are removed
    - can be created and managed using YAML files or kubectl commands
    - provide a way to ensure that essential services are consistently available across all nodes in the cluster    
    - logs are accessed by hostPath volume or DaemonSet pods can forward logs to a centralized logging system

 - StatefulSets:
    - manage the deployment and scaling of stateful applications in Kubernetes
    - provide guarantees about the ordering and uniqueness of pod instances
    - maintain a stable network identity and persistent storage for each pod, even when pods are rescheduled or restarted
    - commonly used for applications that require stable identities and persistent data, such as databases or distributed systems
    - can be created and managed using YAML files or kubectl commands   
    - It is for stateful applications where each pod has its own identity and storage
    - A Headless service is mandatory to be created for a statefulset to function properly.

- Headless Services:
    - a type of Kubernetes service that does not allocate a cluster IP address
    - used to expose pods directly without load balancing or proxying
    - commonly used in conjunction with StatefulSets to provide stable network identities for each pod
    - allows clients to connect directly to individual pod instances using their DNS names
    - can be created and managed using YAML files or kubectl commands   
    - useful for stateful applications that require direct access to specific pod instances, such as databases or clustered applications
    - When a headless service is created, Kubernetes does not assign it a cluster IP address. Instead, it creates DNS records for each pod that matches the service's selector. This allows clients to resolve the DNS name of the headless service to the individual pod IP addresses, enabling direct communication with specific pod instances.
    - when a headless sdervie is hit, it will give all the pod IPs. It is for data repplication and clustering of stateful applications(like DBs  etc).
    - It is mandatory to create a headless service for statefulsets. 


Deployment vs Statefulset vs Daemonset:
| Feature               | Deployment                                  | StatefulSet                                   | DaemonSet                                    |
|-----------------------|---------------------------------------------|-----------------------------------------------|----------------------------------------------|
| Purpose               | Manages stateless applications               | Manages stateful applications                  | Ensures a pod runs on all or specific nodes |
| Pod Identity          | Pods are interchangeable                     | Each pod has a unique identity and stable network ID | Pods run on all or specific nodes            |
| Storage               | Typically uses shared storage or no storage  | Provides stable, persistent storage for each pod | Can use hostPath or other storage types       |
| Scaling               | Easy to scale up or down                      | Scaling maintains pod identity and order       | Not typically scaled; runs on all nodes         |
| Update Strategy       | Supports rolling updates and rollbacks       | Supports rolling updates with ordered pod termination | Updates can be applied to all pods simultaneously |
| Use Cases             | Web servers, APIs, front-end applications | Databases, distributed systems, stateful apps | Log collectors, monitoring agents, network plugins |
| Network Identity      | Pods share the same network identity         | Each pod has a unique network identity         | Pods share the same network identity          |
| Pod Scheduling      | Pods can be scheduled on any node            | Pods are scheduled based on their identity and storage | Pods are scheduled on all or specific nodes   |    


- Volumes:
    - provide persistent storage for pods in a Kubernetes cluster
    - allow data to persist beyond the lifecycle of individual pods, enabling stateful applications
    - can be used to share data between containers within the same pod
    - support various types of storage backends, including local storage, network-attached storage, and cloud-based storage solutions
    - can be defined in pod specifications and mounted into containers at specified paths
    - help ensure data durability and availability for applications running in Kubernetes
  - Static provisioning:
      - An administrator manually creates PersistentVolumes (PVs) in the cluster.
      - Users create PersistentVolumeClaims (PVCs) to request storage from the available PVs.
      - The PVC is bound to a matching PV based on size and access modes.
  - Dynamic provisioning:
      - Storage class is created by the administrator to define different types of storage (e.g., SSD, HDD) and their parameters.
      - Users create PVCs without pre-existing PVs.
      - The cluster automatically provisions a new PV based on the PVC's specifications using StorageClasses.      



